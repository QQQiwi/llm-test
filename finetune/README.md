# Содержание

Данные, которые были получены вследствие парсинга сайтов и ресерча на Kaggle,
были предобработаны и сохранены в качестве выборки для обучения.

На данный момент доступны:

* [x] llama2-7b
* [ ] llama2-13b

## Параметры обучения llama2-7b

Было применено Low-Rank Adaptation.

* lora_alpha = 16
* lora_dropout = 0
* lora_r = 16
* gradient_accumulation_steps = 4
* оптимизатор: "adamw_8bit"
* количество эпох: 60
* weight_decay = 0.01

Затем применялось 8-битное квантование и веса модели сохранялись в формат
**gguf**.

После этого был создан Modelfile ```macllama2-ft.modelfile```, и с помощью него
и весов была инициализирована LLM модель, доступная через интерфейс Ollama.